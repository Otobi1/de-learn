{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6017626f-c7df-4913-a889-bb06587080da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607f9bd1-8173-4a4b-ac45-c78bf50b9a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/09 20:11:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName('test') \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    \t.config(\"spark.driver.memory\", \"4g\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac71f80-db3b-4724-bcca-0bb0dea7f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('data/raw/green/2021/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2b52e5-1a21-41ce-b3f9-e364f5ec37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_pd = pd.read_csv('data/raw/green/2021/01/green_tripdata_2021_01.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87f248c-73b3-48fc-82af-0aec2818fb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd59dfd5-68ad-4c96-b493-013a69304e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-02 12:48:43</td>\n",
       "      <td>2021-01-02 13:54:15</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>25.76</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>12.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>92.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-02 12:16:47</td>\n",
       "      <td>2021-01-02 12:24:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-02 12:07:17</td>\n",
       "      <td>2021-01-02 12:12:06</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-02 12:32:45</td>\n",
       "      <td>2021-01-02 12:59:46</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>11.88</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-02 12:02:46</td>\n",
       "      <td>2021-01-02 12:09:02</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0           2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1           2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2           2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3           2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4           2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "..        ...                  ...                   ...                ...   \n",
       "995         2  2021-01-02 12:48:43   2021-01-02 13:54:15                  N   \n",
       "996         1  2021-01-02 12:16:47   2021-01-02 12:24:56                  N   \n",
       "997         2  2021-01-02 12:07:17   2021-01-02 12:12:06                  N   \n",
       "998         2  2021-01-02 12:32:45   2021-01-02 12:59:46                  N   \n",
       "999         2  2021-01-02 12:02:46   2021-01-02 12:09:02                  N   \n",
       "\n",
       "     RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0             1            43           151                1           1.01   \n",
       "1             1           166           239                1           2.53   \n",
       "2             1            41            42                1           1.12   \n",
       "3             1           168            75                1           1.99   \n",
       "4             2           265           265                3           0.00   \n",
       "..          ...           ...           ...              ...            ...   \n",
       "995           1            15           177                1          25.76   \n",
       "996           1           116            74                1           2.00   \n",
       "997           1            42            41                1           0.87   \n",
       "998           1            82           218                1          11.88   \n",
       "999           1           166           116                1           0.90   \n",
       "\n",
       "     fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0            5.5    0.5      0.5        0.00          0.00        NaN   \n",
       "1           10.0    0.5      0.5        2.81          0.00        NaN   \n",
       "2            6.0    0.5      0.5        1.00          0.00        NaN   \n",
       "3            8.0    0.5      0.5        0.00          0.00        NaN   \n",
       "4          -52.0    0.0     -0.5        0.00          0.00        NaN   \n",
       "..           ...    ...      ...         ...           ...        ...   \n",
       "995         77.0    0.0      0.5        2.75         12.24        NaN   \n",
       "996          9.0    0.0      0.5        1.95          0.00        NaN   \n",
       "997          5.5    0.0      0.5        0.00          0.00        NaN   \n",
       "998         35.0    0.0      0.5        0.00          0.00        NaN   \n",
       "999          6.0    0.0      0.5        0.00          0.00        NaN   \n",
       "\n",
       "     improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                      0.3          6.80             2          1   \n",
       "1                      0.3         16.86             1          1   \n",
       "2                      0.3          8.30             1          1   \n",
       "3                      0.3          9.30             2          1   \n",
       "4                     -0.3        -52.80             3          1   \n",
       "..                     ...           ...           ...        ...   \n",
       "995                    0.3         92.79             1          1   \n",
       "996                    0.3         11.75             1          1   \n",
       "997                    0.3          6.30             2          1   \n",
       "998                    0.3         35.80             2          1   \n",
       "999                    0.3          6.80             2          1   \n",
       "\n",
       "     congestion_surcharge  \n",
       "0                    0.00  \n",
       "1                    2.75  \n",
       "2                    0.00  \n",
       "3                    0.00  \n",
       "4                    0.00  \n",
       "..                    ...  \n",
       "995                  0.00  \n",
       "996                  0.00  \n",
       "997                  0.00  \n",
       "998                  0.00  \n",
       "999                  0.00  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b821ef1b-dc21-4013-9b39-b226d73cae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('lpep_pickup_datetime', StringType(), True), StructField('lpep_dropoff_datetime', StringType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('RatecodeID', LongType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('ehail_fee', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('payment_type', LongType(), True), StructField('trip_type', LongType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_green_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd38942-7f95-4f53-9202-6cc119b33170",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_schema = \\\n",
    "            types.StructType([\n",
    "            types.StructField('VendorID', types.IntegerType(), True), \n",
    "            types.StructField('lpep_pickup_datetime', types.TimestampType(), True), \n",
    "            types.StructField('lpep_dropoff_datetime', types.TimestampType(), True), \n",
    "            types.StructField('store_and_fwd_flag', types.StringType(), True), \n",
    "            types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "            types.StructField('PULocationID', types.IntegerType(), True), \n",
    "            types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "            types.StructField('passenger_count', types.IntegerType(), True), \n",
    "            types.StructField('trip_distance', types.DoubleType(), True), \n",
    "            types.StructField('fare_amount', types.DoubleType(), True), \n",
    "            types.StructField('extra', types.DoubleType(), True), \n",
    "            types.StructField('mta_tax', types.DoubleType(), True), \n",
    "            types.StructField('tip_amount', types.DoubleType(), True), \n",
    "            types.StructField('tolls_amount', types.DoubleType(), True), \n",
    "            types.StructField('ehail_fee', types.DoubleType(), True), \n",
    "            types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "            types.StructField('total_amount', types.DoubleType(), True), \n",
    "            types.StructField('payment_type', types.IntegerType(), True), \n",
    "            types.StructField('trip_type', types.IntegerType(), True), \n",
    "            types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "421372ad-5dd0-4361-8807-6e8c208bdaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/1\n",
      "processing data for 2021/2\n",
      "processing data for 2021/3\n",
      "processing data for 2021/4\n",
      "processing data for 2021/5\n",
      "processing data for 2021/6\n",
      "processing data for 2021/7\n",
      "processing data for 2021/8\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/home/tobi/code/data/raw/green/2021/08.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/raw/green/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/pq/green/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m df_green \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread \\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mschema(green_schema) \\\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;241m.\u001b[39mcsv(input_path)\n\u001b[1;32m     13\u001b[0m df_green \\\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m4\u001b[39m) \\\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;241m.\u001b[39mparquet(output_path)\n",
      "File \u001b[0;32m~/spark/spark-3.4.3-bin-hadoop3/python/pyspark/sql/readwriter.py:727\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/spark/spark-3.4.3-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/spark/spark-3.4.3-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/home/tobi/code/data/raw/green/2021/08."
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "for month in range (1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    \n",
    "    input_path = f'data/raw/green/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/green/{year}/{month:02d}/'\n",
    "\n",
    "    df_green = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(green_schema) \\\n",
    "        .csv(input_path)\n",
    "    \n",
    "    df_green \\\n",
    "        .repartition(4) \\\n",
    "        .write.mode(\"overwrite\") \\\n",
    "        .parquet(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15947cc2-91c0-4a27-b435-5d5acb5ce2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4e0e8a-3c51-4a4f-9eb3-6fbe35077ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_pd = pd.read_csv('data/raw/yellow/2021/01/yellow_tripdata_2021_01.csv.gz', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f48f08d-e0ca-4d1e-8287-d41829065cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('VendorID', LongType(), True), StructField('tpep_pickup_datetime', StringType(), True), StructField('tpep_dropoff_datetime', StringType(), True), StructField('passenger_count', LongType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', LongType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('payment_type', LongType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_yellow_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d898ac-e84c-4d87-b5d7-e2a86fe42afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_schema = \\\n",
    "        types.StructType([\n",
    "            types.StructField('VendorID', types.IntegerType(), True), \n",
    "            types.StructField('tpep_pickup_datetime', types.TimestampType(), True), \n",
    "            types.StructField('tpep_dropoff_datetime', types.TimestampType(), True), \n",
    "            types.StructField('passenger_count', types.IntegerType(), True), \n",
    "            types.StructField('trip_distance', types.DoubleType(), True), \n",
    "            types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "            types.StructField('store_and_fwd_flag', types.StringType(), True), \n",
    "            types.StructField('PULocationID', types.IntegerType(), True), \n",
    "            types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "            types.StructField('payment_type', types.IntegerType(), True), \n",
    "            types.StructField('fare_amount', types.DoubleType(), True), \n",
    "            types.StructField('extra', types.DoubleType(), True), \n",
    "            types.StructField('mta_tax', types.DoubleType(), True), \n",
    "            types.StructField('tip_amount', types.DoubleType(), True), \n",
    "            types.StructField('tolls_amount', types.DoubleType(), True), \n",
    "            types.StructField('improvement_surcharge', types.DoubleType(), True), \n",
    "            types.StructField('total_amount', types.DoubleType(), True), \n",
    "            types.StructField('congestion_surcharge', types.DoubleType(), True)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39e7538a-4b88-4b1c-800d-d194f2736458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/09 20:56:35 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-9c9fd9aa-97d0-48c5-94bd-b8caa04467e2. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-9c9fd9aa-97d0-48c5-94bd-b8caa04467e2\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:178)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:113)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:359)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2048)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2175)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2081)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "for month in range (1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "    \n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'\n",
    "\n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "    \n",
    "    df_yellow \\\n",
    "        .repartition(4) \\\n",
    "        .write.mode(\"overwrite\") \\\n",
    "        .parquet(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb1563-6fa6-4599-adb6-48f7f1bb5544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
